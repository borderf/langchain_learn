{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e55e0d7",
   "metadata": {},
   "source": [
    "### 1. ä¸ºä»€ä¹ˆéœ€è¦Runtime Configuration\n",
    "åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç»å¸¸é‡åˆ°éœ€æ±‚ï¼šåŒä¸€ä¸ªGraphï¼Œåœ¨ä¸åŒçš„è°ƒç”¨åœºæ™¯ä¸‹ï¼Œéœ€è¦ä½¿ç”¨ä¸åŒçš„é…ç½®å‚æ•°ã€‚\n",
    "æ¯”å¦‚ï¼š\n",
    "- æœ‰æ—¶å€™æˆ‘ä»¬å¸Œæœ›Graphä½¿ç”¨ä¸åŒçš„LLMæ¨¡å‹\n",
    "- æœ‰æ—¶å€™æˆ‘ä»¬å¸Œæœ›Graphä½¿ç”¨ä¸åŒçš„Promptæ¨¡æ¿\n",
    "- æœ‰æ—¶å€™æˆ‘ä»¬å¸Œæœ›æ ¹æ®ä¸åŒçš„ç”¨æˆ·æˆ–ç¯å¢ƒï¼ŒåŠ¨æ€è°ƒæ•´Graphçš„è¡Œä¸ºå‚æ•°\n",
    "å¦‚æœæ¯æ¬¡éƒ½è¦é‡æ–°å®šä¹‰Graphæˆ–è€…ä¿®æ”¹ä»£ç ï¼Œå°±å¤ªéº»çƒ¦äº†ã€‚è¿™æ—¶å€™ï¼ŒRuntime Configurationï¼ˆè¿è¡Œæ—¶é…ç½®ï¼‰å°±æ´¾ä¸Šç”¨åœºäº†ã€‚\n",
    "Runtime Configuration å…è®¸æˆ‘ä»¬åœ¨è°ƒç”¨Graphæ—¶ï¼ŒåŠ¨æ€åœ°ä¼ é€’é…ç½®å‚æ•°ï¼Œè€Œä¸éœ€è¦ä¿®æ”¹Graphçš„å®šä¹‰æˆ–ä»£ç ã€‚\n",
    "### 2. Runtime Configurationçš„åŸºæœ¬è®¾ç½®æ–¹æ³•\n",
    "å¢åŠ è¿è¡Œæ—¶è®¾ç½®çš„åŸºæœ¬æ­¥éª¤åŒ…æ‹¬ï¼š\n",
    "1. æŒ‡å®šä¸€ä¸ªå…³äºè¿è¡Œæ—¶é…ç½®çš„schemaï¼›\n",
    "2. å°†è¿™ä¸ªschemaå†™å…¥èŠ‚ç‚¹å‡½æ•°æˆ–è€…æ¡ä»¶è¾¹çš„è·¯ç”±å‡½æ•°ä¸­ï¼›\n",
    "3. åœ¨æ­å»ºGraphæ—¶ä¸stateä¸€èµ·ä¼ å…¥StateGraphä¸­ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c2971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my_state_value': '1'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "# ç‰¹å®šé…ç½®çš„schema\n",
    "# è´Ÿè´£å®šä¹‰è¿è¡Œæ—¶é…ç½®çš„ç»“æ„ï¼Œå‘Šè¯‰LangGraphï¼Œæˆ‘ä»¬åœ¨è°ƒç”¨Graphæ—¶å¯ä»¥ä¼ å…¥å“ªäº›é…ç½®å‚æ•°\n",
    "class ContextSchema(TypedDict):\n",
    "    my_runtime_value: str\n",
    "\n",
    "class State(TypedDict):\n",
    "    my_state_value: str\n",
    "\n",
    "# åœ¨èŠ‚ç‚¹å‡½æ•°ä¸­é…ç½®runtimeå‚æ•°\n",
    "# é¦–å…ˆéœ€è¦ä»langgraph.runtimeä¸­å¯¼å…¥Runtimeç±»å‹\n",
    "# Runtimeæ˜¯ä¸€ä¸ªæ³›å‹ç±»å‹ï¼Œæˆ‘ä»¬åœ¨æŒ‡å®šè‡ªå®šä¹‰çš„ContextSchemaæ—¶ï¼Œéœ€è¦ä½¿ç”¨æ–¹æ‹¬å·\n",
    "# ç„¶åï¼Œåœ¨èŠ‚ç‚¹å‡½æ•°çš„å‚æ•°ä¸­æ·»åŠ runtimeå‚æ•°ï¼Œå°†å®ƒçš„ç±»å‹è®¾å®šä¸ºRuntime[ContextSchema]\n",
    "# è¿™æ ·ï¼ŒèŠ‚ç‚¹å‡½æ•°å°±å¯ä»¥è®¿é—®è¿è¡Œæ—¶é…ç½®äº†ã€‚\n",
    "def node(state: State, runtime: Runtime[ContextSchema]):\n",
    "    if runtime.context[\"my_runtime_value\"] == \"a\":\n",
    "        return {\"my_state_value\": \"1\"}\n",
    "    elif runtime.context[\"my_runtime_value\"] == \"b\":\n",
    "        return {\"my_state_value\": \"2\"}\n",
    "    else:\n",
    "        raise ValueError(\"unknown values.\")\n",
    "\n",
    "# æ„å»ºGraphï¼Œå‘Graphä¸­ä¼ å…¥ContextSchema\n",
    "# å…³é”®ç‚¹åœ¨äºStateGraphçš„åˆå§‹åŒ–ï¼Œé™¤äº†ä¼ å…¥Stateï¼Œè¿˜éœ€è¦ä¼ å…¥context_schemaå‚æ•°\n",
    "# è¿™æ ·ï¼ŒLangGraphå°±ä¼šåœ¨è°ƒç”¨Graphæ—¶ï¼Œå°†è¿è¡Œæ—¶é…ç½®ä¼ é€’ç»™èŠ‚ç‚¹å‡½æ•°\n",
    "builder = StateGraph(State, context_schema=ContextSchema)\n",
    "builder.add_node(\"node\", node)\n",
    "builder.add_edge(START, \"node\")\n",
    "builder.add_edge(\"node\", END)\n",
    "graph = builder.compile()\n",
    "# Runtime Configurationçš„ä½¿ç”¨\n",
    "print(graph.invoke({}, context={\"my_runtime_value\": \"a\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d587e73",
   "metadata": {},
   "source": [
    "### 3. Runtime Configurationçš„å®é™…åº”ç”¨\n",
    "#### 3.1 æŒ‡å®šè¿è¡Œæ—¶ä½¿ç”¨çš„Model\n",
    "åœ¨å®é™…å¼€å‘ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦æ ¹æ®ä¸åŒçš„åœºæ™¯ï¼Œä½¿ç”¨ä¸åŒçš„Modelã€‚è¿™æ—¶ï¼Œå°±å¯ä»¥åˆ©ç”¨Runtime Configurationæ¥å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9ff9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ å¥½ï¼ğŸ˜Š æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 13, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '019ca2c30091ea69b09561a86ea9c2ab', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019ca2c2-ff6b-7b83-9863-c56d9c64bdf3-0' usage_metadata={'input_tokens': 13, 'output_tokens': 10, 'total_tokens': 23, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}}\n",
      "content='ä½ å¥½ï¼ğŸ‘‹ å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿæ— è®ºæ˜¯å›ç­”é—®é¢˜ã€æä¾›å»ºè®®ï¼Œè¿˜æ˜¯é—²èŠï¼Œæˆ‘éƒ½å¾ˆä¹æ„å’Œä½ äº¤æµï½ ğŸ˜Š' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 5, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'deepseek-ai/DeepSeek-V3.2', 'system_fingerprint': '', 'id': '019ca2c3030ede7eb90378dc4e9f6837', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019ca2c3-02be-70b3-9920-5a0766539b7c-0' usage_metadata={'input_tokens': 5, 'output_tokens': 32, 'total_tokens': 37, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}}\n",
      "Qwen/Qwen3-8B\n",
      "deepseek-ai/DeepSeek-V3.2\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import TypedDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ContextSchema(TypedDict):\n",
    "    model_type: str\n",
    "\n",
    "MODELS = {\n",
    "    \"qwen\": init_chat_model(model=\"Qwen/Qwen3-8B\", model_provider=\"openai\"),\n",
    "    \"deepseek\": init_chat_model(model=\"deepseek-ai/DeepSeek-V3.2\", model_provider=\"openai\"),\n",
    "}\n",
    "\n",
    "def call_model(state: MessagesState, runtime: Runtime[ContextSchema]):\n",
    "    \"\"\"è·å–è¿è¡Œæ—¶é…ç½®ä¸­çš„model_typeï¼Œæ ¹æ®å…¶åˆå§‹åŒ–å¯¹åº”çš„Model\"\"\"\n",
    "    model_type = (runtime.context or {}).get(\"model_type\", \"qwen\")\n",
    "    # ä»è¿è¡Œæ—¶é…ç½®ä¸­è·å–model_typeï¼Œé»˜è®¤ä½¿ç”¨qwen\n",
    "    model = MODELS[model_type]\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# æ­å»ºGraphä¼ å…¥context_schema\n",
    "builder = StateGraph(MessagesState, context_schema=ContextSchema)\n",
    "builder.add_node(\"node\", call_model)\n",
    "builder.add_edge(START, \"node\")\n",
    "builder.add_edge(\"node\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# ä½¿ç”¨\n",
    "input_message = {\"role\": \"user\", \"content\": \"ä½ å¥½\"}\n",
    "response_1 = graph.invoke({\"messages\": [input_message]}, context={})[\"messages\"][-1]\n",
    "print(response_1)\n",
    "response_2 = graph.invoke({\"messages\": [input_message]}, context={\"model_type\": \"deepseek\"})[\"messages\"][-1]\n",
    "print(response_2)\n",
    "\n",
    "print(response_1.response_metadata[\"model_name\"])\n",
    "print(response_2.response_metadata[\"model_name\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b9980",
   "metadata": {},
   "source": [
    "#### 3.2 æŒ‡å®šè¿è¡Œæ—¶ä½¿ç”¨çš„System Prompt\n",
    "é™¤äº†åŠ¨æ€åˆ‡æ¢æ¨¡å‹ï¼ŒRuntime Configurationçš„å¦ä¸€ä¸ªå¸¸è§çš„åº”ç”¨åœºæ™¯æ˜¯åŠ¨æ€æŒ‡å®šSystem Promptã€‚\n",
    "æ¯”å¦‚ï¼ŒåŒä¸€ä¸ªå®¢æœAgentï¼Œåœ¨å¤„ç†æŠ€æœ¯é—®é¢˜æ—¶éœ€è¦ä½¿ç”¨æŠ€æœ¯æ”¯æŒçš„System Promptï¼Œåœ¨å¤„ç†é€€æ¬¾é—®é¢˜æ—¶éœ€è¦ä½¿ç”¨å®¢æœçš„System Promptã€‚å¦‚æœæ¯æ¬¡éƒ½è¦é‡æ–°å®šä¹‰Graphï¼Œæ˜¾ç„¶ä¸å¤Ÿçµæ´»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5005a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='pythonæ˜¯ä»€ä¹ˆ', additional_kwargs={}, response_metadata={}, id='d409ff1f-eb28-46d0-9a03-907b110213a7'), AIMessage(content='Python æ˜¯ä¸€ç§**é«˜çº§çš„ã€è§£é‡Šå‹çš„ã€é€šç”¨çš„**ç¼–ç¨‹è¯­è¨€ï¼Œç”± **Guido van Rossum** äº 1991 å¹´é¦–æ¬¡å‘å¸ƒï¼Œåå­—æ¥æºäºè‹±å›½å–œå‰§å›¢ä½“ *Monty Python*ã€‚Python çš„è®¾è®¡ç†å¿µå¼ºè°ƒä»£ç çš„**å¯è¯»æ€§**å’Œ**ç®€æ´æ€§**ï¼Œè¿™ä½¿å¾—å®ƒæˆä¸ºåˆå­¦è€…å’Œä¸“ä¸šäººå£«éƒ½å¹¿æ³›ä½¿ç”¨çš„è¯­è¨€ä¹‹ä¸€ã€‚\\n\\n---\\n\\n### âœ… Python çš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š\\n\\n1. **ç®€æ´æ˜“è¯»**  \\n   Python çš„è¯­æ³•ç»“æ„ä¸åƒ C++ã€Java é‚£æ ·ç¹çï¼Œä½¿ç”¨ç¼©è¿›ä»£æ›¿å¤§æ‹¬å·ï¼Œä»£ç æ›´æ¸…æ™°æ˜“è¯»ã€‚\\n\\n2. **è·¨å¹³å°æ€§**  \\n   Python å¯ä»¥åœ¨å¤šç§æ“ä½œç³»ç»Ÿä¸Šè¿è¡Œï¼Œå¦‚ Windowsã€Linuxã€macOS ç­‰ã€‚\\n\\n3. **é¢å‘å¯¹è±¡**  \\n   Python æ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹ï¼ˆOOPï¼‰ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒè¿‡ç¨‹å¼ç¼–ç¨‹ã€‚\\n\\n4. **åŠ¨æ€ç±»å‹**  \\n   å˜é‡ä¸éœ€è¦é¢„å…ˆå£°æ˜ç±»å‹ï¼Œç±»å‹åœ¨è¿è¡Œæ—¶è‡ªåŠ¨è¯†åˆ«ã€‚\\n\\n5. **å¼€æº**  \\n   Python æ˜¯å¼€æºçš„ï¼Œæ‹¥æœ‰å¼ºå¤§çš„ç¤¾åŒºæ”¯æŒï¼Œæœ‰å¾ˆå¤šå…è´¹çš„åº“å’Œæ¡†æ¶ã€‚\\n\\n6. **å¹¿æ³›åº”ç”¨**  \\n   Python è¢«å¹¿æ³›ç”¨äºï¼š\\n   - **Web å¼€å‘**ï¼ˆå¦‚ Djangoã€Flaskï¼‰\\n   - **æ•°æ®ç§‘å­¦**ï¼ˆå¦‚ Pandasã€NumPyã€Matplotlibã€Scikit-learnï¼‰\\n   - **äººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ **ï¼ˆå¦‚ TensorFlowã€PyTorchã€Kerasï¼‰\\n   - **è‡ªåŠ¨åŒ–è„šæœ¬**ï¼ˆå¦‚çˆ¬è™«ã€ç³»ç»Ÿç®¡ç†ï¼‰\\n   - **ç§‘å­¦è®¡ç®—**ï¼ˆå¦‚ SciPyï¼‰\\n   - **æ¸¸æˆå¼€å‘**ï¼ˆå¦‚ Pygameï¼‰\\n   - **ç½‘ç»œçˆ¬è™«**ã€**æ•°æ®åˆ†æ**ã€**å›¾å½¢ç•Œé¢å¼€å‘**ã€**æ•°æ®åº“ç¼–ç¨‹**ç­‰ã€‚\\n\\n---\\n\\n### ğŸ“Œ Python çš„è¯­æ³•ç¤ºä¾‹ï¼š\\n\\n```python\\n# æ‰“å°ä¸€å¥è¯\\nprint(\"Hello, World!\")\\n\\n# å®šä¹‰ä¸€ä¸ªå‡½æ•°\\ndef greet(name):\\n    print(f\"Hello, {name}!\")\\n\\n# è°ƒç”¨å‡½æ•°\\ngreet(\"Alice\")\\n```\\n\\n---\\n\\n### ğŸ§  Python çš„ä¼˜åŠ¿ï¼š\\n\\n- **å­¦ä¹ æ›²çº¿å¹³ç¼“**ï¼šé€‚åˆç¼–ç¨‹æ–°æ‰‹å…¥é—¨ã€‚\\n- **ä¸°å¯Œçš„ç¬¬ä¸‰æ–¹åº“**ï¼šå¯ä»¥è½»æ¾å®Œæˆå„ç§ä»»åŠ¡ï¼Œæ¯”å¦‚æ•°æ®åˆ†æã€Web å¼€å‘ç­‰ã€‚\\n- **å¹¿æ³›ç¤¾åŒºæ”¯æŒ**ï¼šå¤§é‡æ–‡æ¡£ã€æ•™ç¨‹å’Œèµ„æºå¯ä¾›å‚è€ƒã€‚\\n- **å¤šèŒƒå¼**ï¼šæ”¯æŒå¤šç§ç¼–ç¨‹é£æ ¼ï¼ˆå¦‚å‡½æ•°å¼ã€é¢å‘å¯¹è±¡ã€è¿‡ç¨‹å¼ç­‰ï¼‰ã€‚\\n\\n---\\n\\n### ğŸš€ Python çš„åº”ç”¨åœºæ™¯ï¼š\\n\\n| åº”ç”¨é¢†åŸŸ      | å…¸å‹ç”¨é€”                         | å¸¸ç”¨åº“/æ¡†æ¶            |\\n|---------------|----------------------------------|------------------------|\\n| Web å¼€å‘      | æ„å»ºç½‘ç«™ã€Web åº”ç”¨               | Djangoã€Flaskã€FastAPI |\\n| æ•°æ®åˆ†æ      | æ•°æ®æ¸…æ´—ã€å¯è§†åŒ–ã€ç»Ÿè®¡åˆ†æ        | Pandasã€NumPyã€Matplotlib |\\n| äººå·¥æ™ºèƒ½/æœºå™¨å­¦ä¹  | æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ã€å›¾åƒè¯†åˆ«ç­‰       | TensorFlowã€PyTorchã€Scikit-learn |\\n| è‡ªåŠ¨åŒ–è„šæœ¬    | è‡ªåŠ¨å®Œæˆæ–‡ä»¶æ“ä½œã€ç½‘ç»œè¯·æ±‚ç­‰ä»»åŠ¡ | requestsã€osã€sysã€smtplib |\\n| ç§‘å­¦è®¡ç®—      | æ•°å­¦å»ºæ¨¡ã€ç¬¦å·è®¡ç®—               | SciPyã€SymPyã€NumPy |\\n| ç½‘ç»œçˆ¬è™«      | æ¨¡æ‹Ÿæµè§ˆå™¨æŠ“å–ç½‘é¡µä¿¡æ¯           | requestsã€BeautifulSoupã€Selenium |\\n| æ¸¸æˆå¼€å‘      | 2D æ¸¸æˆã€æ•™è‚²ç±»å°æ¸¸æˆç­‰          | Pygame |\\n\\n---\\n\\n### ğŸ§ª Python çš„å®‰è£…ï¼š\\n\\nä½ éœ€è¦å…ˆå®‰è£… Python è§£é‡Šå™¨ã€‚ä¸‹è½½åœ°å€ï¼šhttps://www.python.org/downloads/\\n\\nå®‰è£…åï¼Œå¯ä»¥åœ¨å‘½ä»¤è¡Œè¾“å…¥ä»¥ä¸‹å‘½ä»¤æ¥éªŒè¯æ˜¯å¦å®‰è£…æˆåŠŸï¼š\\n\\n```bash\\npython --version\\n```\\n\\nå¦‚æœçœ‹åˆ°ç±»ä¼¼ `Python 3.11.0` çš„è¾“å‡ºï¼Œè¯´æ˜å®‰è£…æˆåŠŸã€‚\\n\\n---\\n\\n### ğŸ“š Python çš„å®˜æ–¹æ–‡æ¡£ï¼š\\n\\n- å®˜æ–¹æ–‡æ¡£ç½‘å€ï¼šhttps://docs.python.org/3/\\n- é€‚åˆæŸ¥é˜… Python çš„è¯­æ³•ã€åº“å’Œæ¨¡å—ã€‚\\n\\n---\\n\\nå¦‚æœä½ æ˜¯åˆšå¼€å§‹å­¦ç¼–ç¨‹ï¼ŒPython æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é€‰æ‹©ï¼›å¦‚æœä½ å·²ç»æœ‰ä¸€å®šç¼–ç¨‹ç»éªŒï¼Œä¹Ÿå¯ä»¥ç»§ç»­å­¦ä¹ å®ƒæ¥æ‹“å±•æŠ€èƒ½ã€‚éœ€è¦æˆ‘å¸®ä½ å­¦ä¹ ä¸€äº›å…·ä½“çš„æ–¹å‘ï¼ˆå¦‚ Web å¼€å‘ã€æ•°æ®åˆ†æã€çˆ¬è™«ç­‰ï¼‰å—ï¼Ÿ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 880, 'prompt_tokens': 25, 'total_tokens': 905, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '019ca2d4560a29722036d43bd9f522b7', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ca2d4-550a-7d82-a881-d0265e880755-0', usage_metadata={'input_tokens': 25, 'output_tokens': 880, 'total_tokens': 905, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='pythonæ˜¯ä»€ä¹ˆ', additional_kwargs={}, response_metadata={}, id='e7f75df1-3026-49bc-80a2-3e35d39bdc6d'), AIMessage(content='Python æ˜¯ä¸€ç§é«˜çº§çš„ã€é€šç”¨çš„ã€è§£é‡Šå‹çš„ç¼–ç¨‹è¯­è¨€ï¼Œå®ƒä»¥ç®€æ´ã€æ˜“è¯»çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åï¼Œè¢«å¹¿æ³›ç”¨äºå¤šä¸ªé¢†åŸŸï¼Œå¦‚ï¼š\\n\\n- **Web å¼€å‘**ï¼ˆä½¿ç”¨æ¡†æ¶å¦‚ Djangoã€Flaskï¼‰\\n- **æ•°æ®åˆ†æå’Œç§‘å­¦è®¡ç®—**ï¼ˆä½¿ç”¨ NumPyã€Pandasã€Matplotlibï¼‰\\n- **äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ **ï¼ˆä½¿ç”¨ TensorFlowã€PyTorchã€scikit-learnï¼‰\\n- **è‡ªåŠ¨åŒ–è„šæœ¬** å’Œ **è¿ç»´**ï¼ˆä½¿ç”¨ Ansibleã€Fabricï¼‰\\n- **ç½‘ç»œçˆ¬è™«**ï¼ˆä½¿ç”¨ Scrapyã€Requestsã€BeautifulSoupï¼‰\\n- **æ¸¸æˆå¼€å‘**ï¼ˆä½¿ç”¨ Pygameï¼‰\\n- **GUI ç¼–ç¨‹**ï¼ˆä½¿ç”¨ Tkinterã€PyQtã€wxPythonï¼‰\\n- **åµŒå…¥å¼ç³»ç»Ÿ** å’Œ **ç‰©è”ç½‘**ï¼ˆä½¿ç”¨ MicroPythonï¼‰\\n\\n### Python çš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š\\n\\n1. **æ˜“è¯»æ˜“å†™**ï¼š\\n   - è¯­æ³•ç®€æ´ï¼Œæ¥è¿‘è‡ªç„¶è¯­è¨€ï¼Œä¾¿äºåˆå­¦è€…å­¦ä¹ ã€‚\\n   - ä½¿ç”¨ç¼©è¿›æ¥è¡¨ç¤ºä»£ç å—ï¼Œè€Œä¸æ˜¯å¤§æ‹¬å·ã€‚\\n\\n2. **è·¨å¹³å°**ï¼š\\n   - æ”¯æŒ Windowsã€macOSã€Linux ç­‰å¤šç§æ“ä½œç³»ç»Ÿã€‚\\n\\n3. **å¼€æº**ï¼š\\n   - Python æ˜¯å¼€æºçš„ï¼Œè¿™æ„å‘³ç€ä»»ä½•äººéƒ½å¯ä»¥æŸ¥çœ‹ã€ä¿®æ”¹å’Œåˆ†å‘å…¶æºä»£ç ã€‚\\n\\n4. **é¢å‘å¯¹è±¡**ï¼š\\n   - æ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹ï¼ˆOOPï¼‰ï¼Œä¹Ÿå¯ä»¥è¿›è¡Œè¿‡ç¨‹å¼ç¼–ç¨‹ã€‚\\n\\n5. **ä¸°å¯Œçš„åº“å’Œæ¡†æ¶**ï¼š\\n   - Python æ‹¥æœ‰å¤§é‡ç¬¬ä¸‰æ–¹åº“ï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…å¿«é€Ÿå®ç°å¤æ‚åŠŸèƒ½ã€‚\\n\\n6. **å¹¿æ³›ç¤¾åŒºæ”¯æŒ**ï¼š\\n   - Python æœ‰ä¸€ä¸ªæ´»è·ƒçš„ç¤¾åŒºï¼Œæä¾›äº†å¤§é‡çš„æ•™ç¨‹ã€æ–‡æ¡£å’Œé—®é¢˜è§£ç­”ã€‚\\n\\n7. **åŠ¨æ€ç±»å‹**ï¼š\\n   - å˜é‡ä¸éœ€è¦å£°æ˜ç±»å‹ï¼Œè¿è¡Œæ—¶è‡ªåŠ¨æ¨æ–­ã€‚\\n\\n8. **è§£é‡Šå‹è¯­è¨€**ï¼š\\n   - Python ä»£ç é€šè¿‡è§£é‡Šå™¨æ‰§è¡Œï¼Œå¯ä»¥è·¨å¹³å°è¿è¡Œã€‚\\n\\n---\\n\\n### ä¸€ä¸ªç®€å•çš„ Python ç¤ºä¾‹ï¼š\\n\\n```python\\n# è¿™æ˜¯ä¸€ä¸ªæ‰“å°â€œHello, World!â€çš„ Python ç¨‹åº\\nprint(\"Hello, World!\")\\n```\\n\\n### Python çš„ç‰ˆæœ¬ï¼š\\n\\n- **Python 2**ï¼ˆå·²åœæ­¢ç»´æŠ¤ï¼Œä¸æ¨èä½¿ç”¨ï¼‰\\n- **Python 3**ï¼ˆå½“å‰ä¸»æµç‰ˆæœ¬ï¼Œæ¨èä½¿ç”¨ï¼‰\\n\\n---\\n\\n### Python çš„åº”ç”¨åœºæ™¯ï¼š\\n\\n| åº”ç”¨åœºæ™¯ | ä½¿ç”¨ Python çš„åŸå›  |\\n|----------|--------------------|\\n| Web å¼€å‘ | æœ‰ Flaskã€Django ç­‰æˆç†Ÿæ¡†æ¶ |\\n| æ•°æ®åˆ†æ | æœ‰ Pandasã€NumPy ç­‰å¼ºå¤§åº“ |\\n| è‡ªåŠ¨åŒ–è„šæœ¬ | è¯­æ³•ç®€å•ï¼Œé€‚åˆå¿«é€Ÿå¼€å‘ |\\n| AI/ML | æœ‰ä¸°å¯Œçš„ç§‘å­¦è®¡ç®—åº“å’Œæœºå™¨å­¦ä¹ æ¡†æ¶ |\\n| ç½‘ç»œçˆ¬è™« | æœ‰ Requestsã€BeautifulSoup ç­‰åº“æ–¹ä¾¿å¤„ç† HTTP è¯·æ±‚å’Œè§£æç½‘é¡µ |\\n\\n---\\n\\n### Python çš„å­¦ä¹ èµ„æ–™æ¨èï¼š\\n\\n- **å®˜æ–¹æ–‡æ¡£**ï¼šhttps://docs.python.org/zh-cn/3/\\n- **æ•™ç¨‹**ï¼šhttps://www.runoob.com/python/python-tutorial.html\\n- **ä¹¦ç±**ï¼šã€ŠPython ç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹ï¼ˆé€‚åˆåˆå­¦è€…ï¼‰ã€ã€ŠPython Crash Courseã€‹ï¼ˆé€‚åˆåˆå­¦è€…ï¼‰\\n\\nå¦‚æœä½ æ˜¯åˆšå¼€å§‹å­¦ä¹ ç¼–ç¨‹ï¼ŒPython æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„èµ·ç‚¹ï¼›å¦‚æœä½ å·²ç»æœ‰äº†ç»éªŒï¼ŒPython ä¹Ÿå¯ä»¥ä½œä¸ºå¤šè¯­è¨€å¼€å‘ä¸­çš„ä¸€ç§è¾…åŠ©å·¥å…·ã€‚\\n\\nä½ æœ‰å…·ä½“çš„å­¦ä¹ ç›®æ ‡æˆ–é—®é¢˜å—ï¼Ÿæˆ‘å¯ä»¥è¿›ä¸€æ­¥å¸®åŠ©ä½ ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 684, 'prompt_tokens': 24, 'total_tokens': 708, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '019ca2d4dddb1d32459b5c8d7a2e405c', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ca2d4-dd52-7331-aa0c-d6e825faeaa5-0', usage_metadata={'input_tokens': 24, 'output_tokens': 684, 'total_tokens': 708, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.runtime import Runtime\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# å®šä¹‰Runtime Configurationçš„Schema\n",
    "class ContextSchema(TypedDict):\n",
    "    system_prompt: str\n",
    "\n",
    "# å®šä¹‰å¤„ç†System Promptçš„èŠ‚ç‚¹å‡½æ•°\n",
    "def call_model_with_prompt(state: MessagesState, runtime: Runtime[ContextSchema]):\n",
    "    \"\"\"è·å–è¿è¡Œæ—¶é…ç½®ä¸­çš„system_promptï¼Œæ ¹æ®å…¶åˆå§‹åŒ–å¯¹åº”çš„Model\"\"\"\n",
    "    model = init_chat_model(\n",
    "        model=\"Qwen/Qwen3-8B\",\n",
    "        model_provider=\"openai\",\n",
    "    )\n",
    "    system_prompt = (runtime.context or {}).get(\"system_prompt\", \"You are a helpful assistant.\")\n",
    "    system_message = SystemMessage(content=system_prompt)\n",
    "    # å°† System Messageæ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨çš„å¼€å¤´\n",
    "    messages = [system_message] + state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# æ­å»ºGraph\n",
    "builder = StateGraph(MessagesState, context_schema=ContextSchema)\n",
    "builder.add_node(\"model\", call_model_with_prompt)\n",
    "builder.add_edge(START, \"model\")\n",
    "builder.add_edge(\"model\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# ä½¿ç”¨\n",
    "input_message = {\"role\": \"user\", \"content\": \"pythonæ˜¯ä»€ä¹ˆ\"}\n",
    "# ä½¿ç”¨é»˜è®¤çš„system prompt\n",
    "reponse_1 = graph.invoke({\"messages\": [input_message]}, context={})\n",
    "print(reponse_1)\n",
    "\n",
    "response_2 = graph.invoke({\"messages\": [input_message]}, context={\"system_prompt\": \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„pythonåŠ©æ‰‹\"})\n",
    "print(response_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
