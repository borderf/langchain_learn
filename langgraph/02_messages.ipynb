{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e07572",
   "metadata": {},
   "source": [
    "### Message是什么\n",
    "Message是Chat Model中进行信息交流的基本单位，它用于表示聊天模型的输入和输出，以及与对话可能相关的任何额外上下文或元数据。\n",
    "### Message的类型\n",
    "在Langchain中，Message对象主要包括三个要素：\n",
    "- 角色（Role）：定义Message的类型，常见角色如系统、用户；\n",
    "- 内容（Content）：代表Message的实际内容，可以是字符串、图片、视频、文档等；\n",
    "- 元数据（Metadata）：可选项，包括根据聊天模型提供商而异的各种额外元数据，如message IDs、token用量等等。\n",
    "根据role的不同，Message又分为了4种主要类型，包括：\n",
    "- SystemMessage：对应的角色是系统，用来设定模型的基本身份、行为模式，属于一种系统Prompt。\n",
    "- HumanMessage：对应的角色是用户，代表用户输入的信息。\n",
    "- AIMessage：对应的角色是助手（assistant），代表模型生成的回复信息。\n",
    "- ToolMessage：对应的角色是工具，它包含的内容主要是工具的调用。\n",
    "### 三种等价的Prompt格式\n",
    "下面三种消息输入方式是等价的：\n",
    "```python\n",
    "model.invoke(\"Hello\")\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "model.invoke([HumanMessage(\"Hello\")])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85414f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，世界！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 26, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '019c5077395093b851f7e5f9780462b3', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c5077-37e1-7e80-a5ce-b33412c32f37-0', usage_metadata={'input_tokens': 26, 'output_tokens': 4, 'total_tokens': 30, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"将用户输入翻译为中文\"),\n",
    "    HumanMessage(content=\"Hello World!\"),\n",
    "]\n",
    "model = init_chat_model(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    model_provider=\"openai\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=2000,\n",
    "    timeout=None,\n",
    "    max_retries=3,\n",
    "    base_url=\"https://api.siliconflow.cn/v1\",\n",
    ")\n",
    "\n",
    "model.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
