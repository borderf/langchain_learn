"""
æ™ºèƒ½ç¿»è¯‘åŠ©æ‰‹
"""
from langchain.chat_models import init_chat_model
from langchain_core.messages import SystemMessage, HumanMessage


class SmartTranslator:
    def __init__(self):
        self.model = model = init_chat_model(
            model="Qwen/Qwen3-8B",
            model_provider="openai",
            temperature=0.3,
        )

    def translate(self, text: str, target_language: str = "ä¸­æ–‡", style: str = "æ­£å¼"):
        """
        ç¿»è¯‘æ–‡æœ¬
        :param text:    è¦ç¿»è¯‘çš„æ–‡æœ¬
        :param target_language: ç›®æ ‡è¯­è¨€ï¼ˆä¸­æ–‡/è‹±æ–‡/æ—¥æ–‡ç­‰ï¼‰
        :param style:   ç¿»è¯‘é£æ ¼ï¼ˆæ­£å¼/å£è¯­/æ–‡å­¦ç­‰ï¼‰
        """
        SYSTEM_PROMPT = f"""
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚
            ä»»åŠ¡ï¼š
            1.è‡ªåŠ¨æ£€æµ‹è¾“å…¥æ–‡æœ¬çš„è¯­è¨€ï¼›
            2.ç¿»è¯‘æˆ{target_language}
            3.ä½¿ç”¨{style}é£æ ¼
            4.å¦‚æœæœ‰ä¸“ä¸šæœ¯è¯­ï¼Œåœ¨ç¿»è¯‘åç”¨æ‹¬å·æ ‡æ³¨åŸæ–‡
            
            è¾“å‡ºæ ¼å¼ï¼š
            ã€æºè¯­è¨€ã€‘ï¼šxxx
            ã€ç¿»è¯‘ã€‘ï¼šxxx
            ã€æœ¯è¯­è§£é‡Šã€‘ï¼šï¼ˆå¦‚æœæœ‰ï¼‰
        """
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=text),
        ]

        response = self.model.invoke(messages)
        return response.content


if __name__ == '__main__':
    translator = SmartTranslator()
    print("ğŸ¤–æ™ºèƒ½ç¿»è¯‘åŠ©æ‰‹")
    print("*" * 50)
    text1 = "Langchain is a framework for developing applications powered by large language models."
    print(f"ğŸ“åŸæ–‡ï¼š{text1}")
    print(f"ğŸ“ç¿»è¯‘ç»“æœï¼š{translator.translate(text1, "ä¸­æ–‡", "æ­£å¼")}")
