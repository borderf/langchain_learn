from langchain.chat_models import init_chat_model
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

model = init_chat_model(
    model="Qwen/Qwen3-8B",
    model_provider="openai",
    temperature=0.1,
)

messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå•†ä¸šåˆ†æä¸“å®¶"),
]

print("å¼€å§‹è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè¾“å…¥'quit'é€€å‡º")
while True:
    user_input = input("ğŸ˜„ä½ ï¼š")
    if user_input == "quit":
        break

    messages.append(HumanMessage(content=user_input))

    response = model.stream(messages)

    print("ğŸ¤–AIï¼š", end="")

    ai_message_content = ""
    for message in response:
        ai_message_content += message.content
        print(message.content, end="", flush=True)

    messages.append(AIMessage(content=ai_message_content))

    print()
